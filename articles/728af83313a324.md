---
title: "研究室で余ってる計算機を活用してGPUクラスタを構築してみた with kubernetes"
emoji: "✌️"
type: "tech" # tech: 技術記事 / idea: アイデア
topics: ["機械学習", "kubernetes", "DDP", "分散学習"]
published: false
---

# 1. 概要

本記事では、kubernetes を用いて、オンプレミスの計算機サーバー間で分散学習を行う方法・手順について紹介します。
kubernetes 等の必要なコンポーネントの詳細なインストール手順は割愛させていただきます。

## 環境

- master(control plane)１台 × worker ２台でクラスタを構築します。（簡略化のために最小構成にしてます）
- master, worker 共に ubuntu22.04 を使用
  - GPU は NVIDIA を使用

# 2. master ノードのセットアップ

## Kubernetes の動作要件を満たすように設定

指定したカーネルモジュール(overlay, br_netfilter)をシステム起動時に自動的にロードされるようにする

```
cat <<EOF | sudo tee /etc/modules-load.d/containerd.conf
overlay
br_netfilter
EOF

sudo modprobe overlay
sudo modprobe br_netfilter
```

kubernetes のネットワーク設定

```
cat <<EOF | sudo tee /etc/sysctl.d/kubernetes.conf
net.bridge.bridge-nf-call-iptables  = 1
net.ipv4.ip_forward                 = 1
net.bridge.bridge-nf-call-ip6tables = 1
EOF

sudo sysctl --system
```

swap を無効にする

```
sudo swapoff -a
sudo sed -i '/ swap / s/^\(.*\)$/#\1/g' /etc/fstab
```

## コンテナ関連のコンポーネントのインストール & コンテナ内で GPU を使うための設定

1. NVIDIA driver のインストール
2. docker, containerd のインストール
3. nvidia-container-runtime のインストール、ランタイム設定

参考サイト
https://qiita.com/ttsubo/items/c97173e1f04db3cbaeda

## kubernetes 関連コンポーネントのインストール

## kubeadm で Kubernetes クラスタを構築
